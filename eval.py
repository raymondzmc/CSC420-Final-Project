import torch, os, pdb
import numpy as np
import config as cfg
import cv2 as cv
from scipy.misc import imread
import torch.nn.functional as F
from torchvision import transforms
from torch.utils.data import DataLoader

from model import FashionNet
from dataset import FashionDataset

def eval_mask_rcnn(data_path, label_path, results_path, visual_path):
    """
    Evaluate the mask generated by Mask R-CNN for class person
    """

    img_list = [f.split('.')[0] for f in os.listdir(data_path) if f.split('.')[-1] == 'jpg']
    img_list.sort(key=lambda x:int(x.split('.')[0]))
    img_list = img_list[400:]

    classes = [('background', 0), ('person', 1)]
    tp = np.array(len(classes) * [0.])
    fp = np.array(len(classes) * [0.])
    fn = np.array(len(classes) * [0.])
    pixel_accuracy = 0.

    for name in img_list:

        mask = torch.load(os.path.join(results_path, name + '.pth'))
        label = imread(os.path.join(label_path, name + '_person.png'), mode='P')

        # Save Mask R-CNN results for visualization
        save_path = os.path.join(visual_path, name + '.png')
        mask = mask.squeeze(-1).numpy()
        cv.imwrite(save_path, mask * 255)
        pixel_accuracy += (np.sum(mask == label) / mask.size) * 100

        for i, (name, val) in enumerate(classes):
            tp[i] += np.sum((mask == val) & (label == val))
            fp[i] += np.sum((mask == val) & (label != val))
            fn[i] += np.sum((mask != val) & (label == val))

    pixel_accuracy /= len(img_list)

    for i, (name, _) in enumerate(classes):
        accuracy = (tp[i] / (tp[i] + fp[i] + fn[i])) * 100
        print("The accuracy for {} is {:.5f}".format(name, accuracy))
    print("Pixel accuracy: {:.5f}".format(pixel_accuracy))

def eval_fashion(model, test_loader, visual_path, cuda=False, mode='person'):

    pixel_accuracy = 0.

    if mode == 'person':
        classes = [('background', 0), ('person', 1)]
    else:
        classes = [('background', 0),
                   ('skin', 1),
                   ('hair', 2),
                   ('tshirt', 3),
                   ('shoes', 4),
                   ('pants', 5),
                   ('dress', 6)]

    tp = np.array(len(classes) * [0.])
    fp = np.array(len(classes) * [0.])
    fn = np.array(len(classes) * [0.])

    for i, (image, target, img_name) in enumerate(test_loader):

        if cuda:
            image, target = image.cuda(), target.cuda()

        with torch.no_grad():
            output = model(image)

        # Upsample the output to have the same dimension as the original image
        output = F.upsample(output, size=cfg.image_size, mode='bilinear', align_corners=False)

        if mode == 'clothes':
            output = torch.argmax(output.squeeze(0), dim=0).float()
            output = output.unsqueeze(0)
        else:
            output = torch.sigmoid(output).round()

        pixel_accuracy += (len(output[output == target]) / output.numel()) * 100

        for i, (name, val) in enumerate(classes):
            tp[i] += torch.sum((output == val) & (target == val)).item()
            fp[i] += torch.sum((output == val) & (target != val)).item()
            fn[i] += torch.sum((output != val) & (target == val)).item()

        

        # Visualize the results and save visualization at respective path
        save_path = os.path.join(visual_path, img_name[0] + '.png')
        if mode == 'person':
            output = output.squeeze(0).squeeze(0).cpu().numpy()
            cv.imwrite(save_path, output * 255)
        else:
            output = output.squeeze(0).cpu().numpy()
            results = np.zeros((*output.shape, 3))
            for key, val in cfg.color_mapping.items():
                results[output == key] = val
            cv.imwrite(save_path, cv.cvtColor(results.astype('uint8'), cv.COLOR_BGR2RGB))

    pixel_accuracy /= len(test_loader)

    for i, (name, _) in enumerate(classes):
        accuracy = (tp[i] / (tp[i] + fp[i] + fn[i])) * 100
        print("The accuracy for {} is {:.5f}".format(name, accuracy))
    print("Pixel accuracy: {:.5f}".format(pixel_accuracy))


def eval_and_visualize(data_path, label_path, ckpt_path, visual_path, ckpt, mode):
    n_classes = 1 if mode == 'person' else 7

    model = FashionNet(n_classes=n_classes)

    cuda = torch.cuda.is_available()

    if cuda:
        model = model.cuda()

    ckpt_path = os.path.join(ckpt_path, mode)
    model.load_state_dict(torch.load(os.path.join(ckpt_path, "{}.pth".format(ckpt))))

    transform = transforms.Compose([
                transforms.Resize(cfg.input_size),
                transforms.ToTensor(),
                transforms.Normalize(mean=cfg.mean, std=cfg.std)])

    test_set = FashionDataset(cfg.data_path, cfg.label_path, transform, mode=mode, train=False)
    test_loader = DataLoader(test_set, batch_size=1, pin_memory=cuda)

    eval_fashion(model, test_loader, visual_path, cuda=cuda, mode=mode)

if __name__ == "__main__":

    # print("Evaluate the results from Mask R-CNN ...")
    # eval_mask_rcnn(cfg.data_path,
    #                cfg.label_path,
    #                cfg.maskrcnn_path,
    #                cfg.maskrcnn_visual_path)

    # print("Evaluate the results for task 1 ...")
    # eval_and_visualize(cfg.data_path,
    #                    cfg.label_path,
    #                    cfg.ckpt_path,
    #                    cfg.person_path,
    #                    cfg.epochs,
    #                    'person')

    print("Evaluate the results for task 2 ...")
    eval_and_visualize(cfg.data_path,
                       cfg.label_path,
                       cfg.ckpt_path,
                       cfg.clothes_path,
                       cfg.epochs,
                       'clothes')